{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем писать код, необходимо разобраться в решаемой задаче и доступных данных. В этом проекте пользуясь командами и модулями Ipython, работаю с данными об измерениях значений относительной минеральной плотности позвоночника подростков, живущих в Северной Америке (в дальнейшем вместо этого длинного значения буду коротко использовать spnbmd, что и соответствует названию датасета). Эти данные я взяла из сайта https://web.stanford.edu/~hastie/ElemStatLearn/data \n",
    "\n",
    "Основня цель задачи: на основе имеющихся данных анализировать и построить модель, которая будет наилучшим образом прогнозировать изменение spnbmd в зависимости от различных факторов.\n",
    "\n",
    "Данные уже включают в себя присвоенные значения spnbmd, поэтому задача представляет собой машинное обучение с управляемой регрессией:\n",
    "Управляемая (Supervised): известны признаки и цель, и основная задача — обучить модель, которая сможет сопоставить первое со вторым.\n",
    "Модель должна быть:\n",
    "\n",
    "точная  —  чтобы могла прогнозировать значение spnbmd близкое к истинному; \n",
    "интерпретируемая  —  чтобы было возможно понять её прогнозы.\n",
    "Для для ознакомления загрузим фото подростков. Для этого использую numpy и matplotlib.pylab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "im = plt.imread(\"C:\\\\Users\\\\HP\\\\Desktop\\\\подростки.png\")\n",
    "\n",
    "def plti(img, h=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image.\n",
    "    \"\"\"\n",
    "    y = im.shape[0]\n",
    "    x = im.shape[1]\n",
    "    w = (y/x) * h\n",
    "    plt.figure(figsize=(w*2000,h*5))\n",
    "    plt.imshow(im, interpolation=\"nearest\", **kwargs)\n",
    "    plt.axis('off')\n",
    "plti(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для ознакомления с данными использую запрос, а затем загружаю данные \n",
    "import requests\n",
    "import pandas as pd # для работы с матрицами\n",
    "\n",
    "r = requests.get(\"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/bone.info.txt\")\n",
    "\n",
    "# Загружаю данные\n",
    "names = ['idnum', 'ethnic', 'age', 'sex', 'spnbmd']\n",
    "spnbmd = pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\spnbmd.csv')\n",
    "spnbmd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изучаю их, чтобы в дальнейшем преобразовать\n",
    "# idnum - идентификационный номер подростка\n",
    "# ethnic - этническое происхождение\n",
    "# age - среднее значение возраста на основе двух проверок\n",
    "# sex - пол\n",
    "# spnbmd - измерение относительной минеральной плотности позвоночника\n",
    "spnbmd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так как нельзя применить числовой анализ к строкам, конвентирую данные и применяю различные изменения для названия столбцов. \n",
    "\n",
    "spnbmd['sexMale'] = pd.get_dummies(spnbmd['sex'], drop_first = True)\n",
    "spnbmd[['Black', 'Hispanic', 'White']] = pd.get_dummies(spnbmd['ethnic'], drop_first = True)\n",
    "spnbmd = spnbmd.drop('sex', axis = 1)\n",
    "spnbmd = spnbmd.drop('ethnic', axis = 1)\n",
    "spnbmd = spnbmd[['age', 'sexMale', 'Black', 'Hispanic', 'White', 'spnbmd']]\n",
    "spnbmd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После корректировки данных можно приступать к анализу и выбору модели. Прежде чем перейти к созданию модели, нужно выбрать исходный базовый уровень — некое предположение, с которым буду сравнивать результаты работы моделей. Если они окажутся ниже базового уровня, буду считать, что машинное обучение неприменимо для решения этой задачи, или что нужно попробовать иной подход. Для этого вызываю train_test_split из sklearn.model_selection. Разделяю выборку на тестовую и обучающую, выражаю значения для обучающей выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Тренировачные значения для X и Y, выражаю соответствено через features и targets\n",
    "features = spnbmd.drop('spnbmd', axis =1)\n",
    "targets = pd.DataFrame(spnbmd['spnbmd'])\n",
    "\n",
    "# тестовая 30% - обучающая 70%\n",
    "X, X_test, y, y_test = train_test_split(features, targets, test_size = 0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики беру среднюю абсолютную ошибку (mae) в прогнозах. Среднюю абсолютную ошибку легко вычислить и интерпретировать. Записываю функцию для вычисления средней абсолютной ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))\n",
    "\n",
    "baseline_guess = np.median(y)\n",
    "\n",
    "print('Базовое предположение на наборе %0.2f' % baseline_guess)\n",
    "print('Базовая производительность на тестовом наборе: MAE = %0.4f' % mae(y_test, baseline_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя абсолютная ошибка на тестовом наборе составила около 15. Поскольку оцениваем в диапазоне от 1 до 100, то ошибка составляет 15 % — довольно низкий барьер для базовой модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем рассматривать взаимосвязи между моделями, подготавливаю данные. Для устранения пустоты данных заполняю их достаточно простым методом медианного заполнения (median imputation), который заменяет отсутствующие данные средним значениями по соответствующим колонкам.\n",
    "Создаю код Scikit-Learn-объект Imputer с медианной стратегией. Затем обучаю его на обучающих данных (с помощью imputer.fit), и применяю для заполнения отсутствующих значений в обучающем и тестовом наборах (с помощью imputer.transform).\n",
    "\n",
    "Нужно отметить что, признаки измеряются в разных единицах, а значит покрывают разные диапазоны. Это сильно искажает результаты некоторых алгоритмов. Для избежания этого использую масштабирование. Масштабировать буду с помощью приведения каждого признака к диапазону от 0 до 1. Беру все значения признака, выбираю минимальное и делю его на разницу между максимальным и минимальным (диапазон). Такой способ масштабирования часто называют нормализацией. Пользуюсь объектом MinMaxScaler из Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обработка нехватающих значений и масштабирование.\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler \n",
    "\n",
    "# Create an imputer object with a median filling strategy\n",
    "imputer = Imputer(strategy='median')\n",
    "# Train on the training features\n",
    "imputer.fit(features)\n",
    "# Transform both training data and testing data\n",
    "X = imputer.transform(features)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Fit on the training data\n",
    "scaler.fit(X)\n",
    "# Transform both the training and testing data\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "y = np.array(targets).reshape((-1, ))\n",
    "y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иллюстрирую процесс создания, обучения (.fit ) и тестирования (.predict ) на моделях, а также определяю среднюю абсолютную ошибку для каждой модели, чтобы быстро выбрать оптимальную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Модели\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate mean absolute error\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "# Train the model\n",
    "    model.fit(X, y)\n",
    "# Make predictions and evalute\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_mae = mae(y_test, model_pred)\n",
    "# Return the performance metric\n",
    "    return model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr_mae = fit_and_evaluate(lr)\n",
    "print('Linear Regression Performance on the test set: MAE = %0.4f' % lr_mae)\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state=12)\n",
    "random_forest_mae = fit_and_evaluate(random_forest)\n",
    "print('Random Forest Regression Performance on the test set: MAE = %0.4f' % random_forest_mae)\n",
    "\n",
    "gradient_boosted = GradientBoostingRegressor(random_state=12)\n",
    "gradient_boosted_mae = fit_and_evaluate(gradient_boosted)\n",
    "print('Gradient Boosted Regression Performance on the test set: MAE = %0.4f' % gradient_boosted_mae)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=6)\n",
    "knn_mae = fit_and_evaluate(knn)\n",
    "print('K-Nearest Neighbors Regression Performance on the test set: MAE = %0.4f' % knn_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше вычисляла базовый уровень MAE = 0.1548. Полученные результаты моделей оказались значительно лучше, так что нашу задачу можно решить с помощью машинного обучения. Также более наглядно сравнение моделей можно увидеть на графике. Для этого вызываю matplotlib.pyplot, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # рисовать графики\n",
    "%matplotlib inline\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "plt.style.use('fivethirtyeight')\n",
    "figsize(8, 3)\n",
    "\n",
    "# Dataframe to hold the results\n",
    "model_comparison = pd.DataFrame({'model': ['Linear Regression', 'Random Forest', 'Gradient Boosted', 'K-Nearest Neighbors'],\n",
    "                                'mae': [lr_mae, random_forest_mae, gradient_boosted_mae, knn_mae]})\n",
    "\n",
    "# Horizontal bar chart of test mae\n",
    "model_comparison.sort_values('mae', ascending = False).plot(x = 'model', y = 'mae', kind = 'barh', \n",
    "                                                            color = 'red', edgecolor = 'black')\n",
    "\n",
    "# Plot formatting\n",
    "plt.ylabel(''); plt.yticks(size = 14); plt.xlabel('Mean Absolute Error'); plt.xticks(size = 14)\n",
    "plt.title('Модель сравнения для MAE', size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом все эти оптимизации позволили улучшить первоначальную модель на 10%. На основании этих результатов выбираю модель смешанного дерева (Random Forest) и дальше работаю с ним."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Чтобы разобраться как работает модель, определяю какие признаки наиболее важные. Важности признаков позволяют увидеть связь каждого признака с целью прогнозирования. В приведённом ниже коде — обученная модель и с помощью графика feature_results определяю важности признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = pd.DataFrame({'feature': list(features.columns), \n",
    "                                'importance': random_forest.feature_importances_})\n",
    "feature_results = feature_results.sort_values('importance', ascending = False).reset_index(drop=True)\n",
    "\n",
    "figsize(8, 3)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Показать важность признаков на графике\n",
    "feature_results.loc[:5, :].plot(x = 'feature', y = 'importance', \n",
    "                                 edgecolor = 'k',\n",
    "                                 kind='barh', color = 'blue');\n",
    "plt.xlabel('Отношение важности', size = 15); plt.ylabel('')\n",
    "plt.title('Прогнозируемая важность из модели Random Forest', size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно наибольшее влияние оказывает возраст. На основе этих результатов можно наконец-то ответить на один из основных вопросов: самыми важными признаками изменения относительной минеральной плотности позвоночника является признак возраста и пол."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы объяснить, как сформирован одиночный прогноз любой модели машинного обучения использую LIME (Локальные интерпретируемые моделезависимые объяснения). Создаю объясняющий объект (explainer) и передаю ему обучающие данные, информацию о режиме, метки для обучающих данных и имена признаков. Теперь можно передать explainer’у данные наблюдений и функцию прогнозирования, а потом попросить объяснить причину правдивости прогноза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME\n",
    "import lime \n",
    "import lime.lime_tabular\n",
    "\n",
    "# lime explainer object\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data = X, \n",
    "      mode = 'regression', training_labels = y, feature_names = list(features.columns))\n",
    "exp = explainer.explain_instance(X_test[5,:], \n",
    "                                 random_forest.predict)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерпретирую диаграмму так, каждая запись по оси Y обозначает одно значение переменной, а красные и зелёные полосы отражают влияние этого значения на прогноз. Например, согласно верхней записи влияние age больше 0.61, в результате к прогнозу прибавляется 0.15 пунктов. Согласно второй записи влияние sexMale между 0:1, и поэтому к прогнозу прибавляется около 0.07 пунктов. Итоговый прогноз представляет собой сумму интерсепта и влияний каждого из перечисленных значений. Подобные инструменты могут сильно облегчить понимание работы модели и принимать более правильные решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Исспользуя возможности Python, я рассмотрела несколько этапов решения задачи машинного обучения:\n",
    "\n",
    "1)Загрузка данных и корректировка\n",
    "\n",
    "2)Взаимосвязь между моделями\n",
    "\n",
    "3)Выбор признаков и LIME\n",
    "\n",
    "Результаты свидетельствуют, что можно применять машинное обучение для прогнозирования изменения значений относительной минеральной плотности позвоночника подростков на основе доступных данных. А также можно опираться на возраст для определения среднего значения относительной минеральной плотности позвоночника. Наилучшее значение показала модель Random Forest(смешанного леса), также удалось на тестовых данных добиться погрешности в пределах 6%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
